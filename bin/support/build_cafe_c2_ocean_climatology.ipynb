{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook processes CAFE v3 ocean daily data for building climatologies. Only the last 100 years are used.\n",
    "Currently only runs on Raijin, as control run data not yet transferred to Canberra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T07:51:03.421327Z",
     "start_time": "2018-06-12T07:50:47.082626Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import packages -----\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from ipywidgets import FloatProgress\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_CAFE</th>\n",
       "      <th>name_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sst</td>\n",
       "      <td>sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patm_t</td>\n",
       "      <td>patm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eta_t</td>\n",
       "      <td>eta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sss</td>\n",
       "      <td>sss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u_surf</td>\n",
       "      <td>u_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>v_surf</td>\n",
       "      <td>v_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mld</td>\n",
       "      <td>mld</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name_CAFE name_std\n",
       "0       sst      sst\n",
       "1    patm_t     patm\n",
       "2     eta_t      eta\n",
       "3       sss      sss\n",
       "4    u_surf      u_s\n",
       "5    v_surf      v_s\n",
       "6       mld      mld"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard naming -----\n",
    "fields = pd.DataFrame( \\\n",
    "        {'name_CAFE': ['sst', 'patm_t', 'eta_t', 'sss', 'u_surf', 'v_surf', 'mld'],\n",
    "         'name_std' : ['sst', 'patm',   'eta',   'sss', 'u_s',    'v_s',    'mld']}\n",
    "                     )\n",
    "name_dict = fields.set_index('name_CAFE').to_dict()['name_std']\n",
    "\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only use last 100 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T07:52:05.026523Z",
     "start_time": "2018-06-12T07:51:54.334817Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data3/hh5/public/apps/miniconda3/envs/analysis3/lib/python3.6/site-packages/xarray/conventions.py:416: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using dummy netCDF4.datetime objects instead, reason: dates out of range\n",
      "  result = decode_cf_datetime(example_value, units, calendar)\n",
      "/g/data3/hh5/public/apps/miniconda3/envs/analysis3/lib/python3.6/site-packages/xarray/conventions.py:435: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using dummy netCDF4.datetime objects instead, reason: dates out of range\n",
      "  calendar=self.calendar)\n"
     ]
    }
   ],
   "source": [
    "# Loop over all paths -----\n",
    "base = '/g/data1/v14/coupled_model/v2/OUTPUT/'\n",
    "years = range(400,500)\n",
    "\n",
    "paths = []\n",
    "for year in years:\n",
    "    path = base + 'ocean_daily_0' + str(year) + '_01_01.nc'\n",
    "    paths.append(path)\n",
    "\n",
    "ds = xr.open_mfdataset(paths, autoclose=True) \\\n",
    "       .drop(['average_T1','average_T2','average_DT','time_bounds',\n",
    "              'area_t','area_u','geolat_c','geolat_t','ht','mld_sq']) \\\n",
    "       .rename(name_dict)\n",
    "        \n",
    "if 'xu_ocean' in ds.dims:\n",
    "    ds = ds.rename({'xu_ocean':'lon_u','yu_ocean':'lat_u'})\n",
    "if 'xt_ocean' in ds.dims:\n",
    "    ds = ds.rename({'xt_ocean':'lon_t','yt_ocean':'lat_t'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use year 2016 as time -----\n",
    "path = '/g/data1/v14/forecast/v1/yr2016/mn1/OUTPUT.1/ocean_daily*.nc'\n",
    "dataset = xr.open_mfdataset(path, autoclose=True)\n",
    "time_use = xr.concat([dataset.time[:59], dataset.time[60:366]],dim='time')\n",
    "time_ly = dataset.time[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make month_day array of month-day -----\n",
    "m = [str(ds.time.values[i].timetuple()[1]).zfill(2) + '-' for i in range(len(ds.time))]\n",
    "d = [str(ds.time.values[i].timetuple()[2]).zfill(2) for i in range(len(ds.time))]\n",
    "md = np.core.defchararray.add(m, d)\n",
    "\n",
    "# Replace time array with month_day array and groupby -----\n",
    "ds['time'] = md\n",
    "clim = ds.groupby('time').mean(dim='time',keep_attrs=True)\n",
    "clim['time'] = time_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate Feb 28th as Feb 29th to deal with leap years -----\n",
    "clim_ly = clim.copy().sel(time='2016-02-28')\n",
    "clim_ly['time'] = np.array([time_ly.values])\n",
    "clim = xr.auto_combine([clim,clim_ly]).sortby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the climatology -----\n",
    "save_fldr = '/g/data1/v14/squ027/tmp/'\n",
    "clim.to_netcdf(save_fldr + 'cafe.c2.ocean.400_499.clim.nc', mode = 'w',\n",
    "               encoding = {'time':{'dtype':'float','calendar':'JULIAN',\n",
    "                           'units':'days since 0001-01-01 00:00:00'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3]",
   "language": "python",
   "name": "conda-env-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
