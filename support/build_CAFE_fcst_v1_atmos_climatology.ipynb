{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook saves CAFE v1 atmospheric daily climatologies in a single dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT: If adapting this code to save other climatologies, be careful to only include full years, as pyLatte will compute monthly climatologies from the saved daily climatologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pylatte import utils\n",
    "from ipywidgets import FloatProgress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_CAFE</th>\n",
       "      <th>name_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lwflx</td>\n",
       "      <td>lwf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shflx</td>\n",
       "      <td>shf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tau_x</td>\n",
       "      <td>tau_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tau_y</td>\n",
       "      <td>tau_y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_ref</td>\n",
       "      <td>t_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q_ref</td>\n",
       "      <td>q_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u_ref</td>\n",
       "      <td>u_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>v_ref</td>\n",
       "      <td>v_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t_ref_min</td>\n",
       "      <td>t_ref_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t_ref_max</td>\n",
       "      <td>t_ref_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>t_surf</td>\n",
       "      <td>t_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ps</td>\n",
       "      <td>p_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>slp</td>\n",
       "      <td>slp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>h500</td>\n",
       "      <td>h500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hght</td>\n",
       "      <td>gh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sphum</td>\n",
       "      <td>sphum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ucomp</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vcomp</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>precip</td>\n",
       "      <td>precip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lwdn_sfc</td>\n",
       "      <td>lwf_dn_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lwup_sfc</td>\n",
       "      <td>lwf_up_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>olr</td>\n",
       "      <td>olwr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>swdn_sfc</td>\n",
       "      <td>swf_dn_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>swup_sfc</td>\n",
       "      <td>swf_up_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>swup_toa</td>\n",
       "      <td>swf_up_toa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>high_cld_amt</td>\n",
       "      <td>high_cld_amt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>low_cld_amt</td>\n",
       "      <td>low_cld_amt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mid_cld_amt</td>\n",
       "      <td>mid_cld_amt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tot_cld_amt</td>\n",
       "      <td>tot_cld_amt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>latb</td>\n",
       "      <td>lat_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lonb</td>\n",
       "      <td>lon_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name_CAFE      name_std\n",
       "0          lwflx           lwf\n",
       "1          shflx           shf\n",
       "2          tau_x         tau_x\n",
       "3          tau_y         tau_y\n",
       "4          t_ref         t_ref\n",
       "5          q_ref         q_ref\n",
       "6          u_ref         u_ref\n",
       "7          v_ref         v_ref\n",
       "8      t_ref_min     t_ref_min\n",
       "9      t_ref_max     t_ref_max\n",
       "10        t_surf           t_s\n",
       "11            ps           p_s\n",
       "12           slp           slp\n",
       "13          h500          h500\n",
       "14          hght            gh\n",
       "15         sphum         sphum\n",
       "16          temp          temp\n",
       "17         ucomp             u\n",
       "18         vcomp             v\n",
       "19        precip        precip\n",
       "20      lwdn_sfc      lwf_dn_s\n",
       "21      lwup_sfc      lwf_up_s\n",
       "22           olr          olwr\n",
       "23      swdn_sfc      swf_dn_s\n",
       "24      swup_sfc      swf_up_s\n",
       "25      swup_toa    swf_up_toa\n",
       "26  high_cld_amt  high_cld_amt\n",
       "27   low_cld_amt   low_cld_amt\n",
       "28   mid_cld_amt   mid_cld_amt\n",
       "29   tot_cld_amt   tot_cld_amt\n",
       "30          latb         lat_2\n",
       "31          lonb         lon_2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Location of forecast data -----\n",
    "fcst_folder = '/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/'\n",
    "fcst_filename = 'atmos_daily*'\n",
    "fields = pd.DataFrame( \\\n",
    "        {'name_CAFE': ['lwflx', 'shflx', 'tau_x', 'tau_y', 't_ref', 'q_ref', 'u_ref', 'v_ref', 't_ref_min',\n",
    "                       't_ref_max', 't_surf', 'ps',  'slp', 'h500', 'hght', 'sphum', 'temp', 'ucomp', 'vcomp',\n",
    "                       'precip', 'lwdn_sfc', 'lwup_sfc', 'olr',  'swdn_sfc', 'swup_sfc', 'swup_toa',   \n",
    "                       'high_cld_amt', 'low_cld_amt', 'mid_cld_amt', 'tot_cld_amt', 'latb',  'lonb'],\n",
    "         'name_std' : ['lwf',   'shf',   'tau_x', 'tau_y', 't_ref', 'q_ref', 'u_ref', 'v_ref', 't_ref_min',\n",
    "                       't_ref_max', 't_s',    'p_s', 'slp', 'h500', 'gh',   'sphum', 'temp', 'u',     'v',\n",
    "                       'precip', 'lwf_dn_s', 'lwf_up_s', 'olwr', 'swf_dn_s', 'swf_up_s', 'swf_up_toa', \n",
    "                       'high_cld_amt', 'low_cld_amt', 'mid_cld_amt', 'tot_cld_amt', 'lat_2', 'lon_2']}\n",
    "                     )\n",
    "name_dict = fields.set_index('name_CAFE').to_dict()['name_std']\n",
    "\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial dates to include (takes approximately 1 min 30 sec per date) -----\n",
    "init_dates = pd.date_range('2002-2','2016-5' , freq='1MS')\n",
    "\n",
    "# Ensembles to include -----\n",
    "ensembles = range(1,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack data into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c31eb97378c4e6f87e11dcbe916b71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FloatProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FloatProgress(value=0.0, description='Loading...', max=1892.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate progress bar -----\n",
    "f = FloatProgress(min=0, max=len(init_dates)*len(ensembles), description='Loading...') \n",
    "display(f)\n",
    "\n",
    "# Loop over initial dates -----\n",
    "fcst_list = []\n",
    "for init_date in init_dates:\n",
    "    year = init_date.year\n",
    "    month = init_date.month\n",
    "    \n",
    "    # Loop over ensembles -----\n",
    "    ens_list = []\n",
    "    for ensemble in ensembles:\n",
    "        # Signal to increment the progress bar -----\n",
    "        f.value += 1 \n",
    "        \n",
    "        # Stack ensembles into a list -----\n",
    "        path = fcst_folder + '/yr' + str(year) + '/mn' + str(month) + \\\n",
    "               '/OUTPUT.' + str(ensemble) + '/' + fcst_filename + '.nc'\n",
    "        dataset = xr.open_mfdataset(path, autoclose=True)\n",
    "        ens_list.append(dataset.drop(['average_T1','average_T2','average_DT','time_bounds']) \\\n",
    "                               .rename(name_dict))\n",
    "        \n",
    "    # Concatenate ensembles -----\n",
    "    ens_object = xr.concat(ens_list, dim='ensemble')\n",
    "    ens_object['ensemble'] = ensembles\n",
    "    \n",
    "    # Stack concatenated ensembles into a list for each initial date -----                       \n",
    "    fcst_list.append(ens_object)\n",
    "\n",
    "# Concatenate initial dates -----\n",
    "ds = xr.concat(fcst_list, dim='time')\n",
    "\n",
    "# Rechunk for chunksizes of at least 1,000,000 elements -----\n",
    "ds = utils.prune(ds.chunk(chunks={'ensemble' : len(ds.ensemble), \n",
    "                                  'time' : len(ds.time)}).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load one 366 day long year to provide time array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = fcst_folder + '/yr2016/mn1/OUTPUT.1/' + fcst_filename + '.nc'\n",
    "dataset = xr.open_mfdataset(path, autoclose=True)\n",
    "time_use = dataset.time[:366]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save each variable separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in fields['name_std']:\n",
    "    with utils.timer():\n",
    "        print(f'Saving climatology for {variable}...')\n",
    "        da = ds[variable]\n",
    "        months = np.array([str(i)+'-' for i in pd.DatetimeIndex(ds.time.values).month.values])\n",
    "        days = np.array([str(i) for i in pd.DatetimeIndex(ds.time.values).day.values])\n",
    "        month_day = np.core.defchararray.add(months, days)\n",
    "\n",
    "        da['time'] = month_day\n",
    "\n",
    "        da_clim = da.mean(dim='ensemble',keep_attrs=True).groupby('time').mean(dim='time',keep_attrs=True)\n",
    "        da_clim['time'] = time_use\n",
    "\n",
    "        da_clim.time.attrs['long_name'] = 'time'\n",
    "        da_clim.time.attrs['cartesian_axis'] = 'T'\n",
    "        da_clim.time.attrs['calendar_type'] = 'JULIAN'\n",
    "        da_clim.time.attrs['bounds'] = 'time_bounds'\n",
    "\n",
    "        savename = 'cafe.fcst.v1.atmos.'+variable+'.2002020112_2018123112.clim.nc'\n",
    "\n",
    "        da_clim.to_netcdf(path='/OSM/CBR/OA_DCFP/data/intermediate_products/pylatte_climatologies/' + savename,\n",
    "                          mode = 'w',\n",
    "                          encoding = {'time':{'dtype':'float','calendar':'JULIAN',\n",
    "                                              'units':'days since 0001-01-01 00:00:00'}})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pylatte_env]",
   "language": "python",
   "name": "conda-env-pylatte_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
