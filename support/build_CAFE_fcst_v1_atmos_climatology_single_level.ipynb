{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook saves CAFE v1 atmospheric daily climatologies in a single dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT: If adapting this code to save other climatologies, be careful to only include full years, as pyLatte will compute monthly climatologies from the saved daily climatologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T08:36:24.151116Z",
     "start_time": "2018-05-02T08:36:22.966530Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pylatte import utils\n",
    "from ipywidgets import FloatProgress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T08:36:24.974949Z",
     "start_time": "2018-05-02T08:36:24.900122Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_CAFE</th>\n",
       "      <th>name_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precip</td>\n",
       "      <td>precip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name_CAFE name_std\n",
       "0    precip   precip"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Location of forecast data -----\n",
    "fcst_folder = '/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/'\n",
    "fcst_filename = 'atmos_daily*'\n",
    "\n",
    "fields = pd.DataFrame( \\\n",
    "        {'name_CAFE': ['hght', 'sphum', 'temp', 'ucomp', 'vcomp'],\n",
    "         'name_std' : ['gh',   'sphum', 'temp', 'u',     'v']}\n",
    "                     )\n",
    "name_dict = fields.set_index('name_CAFE').to_dict()['name_std']\n",
    "\n",
    "fields = pd.DataFrame( \\\n",
    "        {'name_CAFE': ['lwflx', 'shflx', 'tau_x', 'tau_y', 't_ref', 'q_ref', 'u_ref', 'v_ref', 't_ref_min',\n",
    "                       't_ref_max', 't_surf', 'ps',  'slp', 'h500', 'precip', 'lwdn_sfc', 'lwup_sfc', 'olr',  \n",
    "                       'swdn_sfc', 'swup_sfc', 'swup_toa',   'high_cld_amt', 'low_cld_amt', 'mid_cld_amt', 'tot_cld_amt'],\n",
    "         'name_std' : ['lwf',   'shf',   'tau_x', 'tau_y', 't_ref', 'q_ref', 'u_ref', 'v_ref', 't_ref_min',\n",
    "                       't_ref_max', 't_s',    'p_s', 'slp', 'h500', 'precip', 'lwf_dn_s', 'lwf_up_s', 'olwr', \n",
    "                       'swf_dn_s', 'swf_up_s', 'swf_up_toa', 'high_cld_amt', 'low_cld_amt', 'mid_cld_amt', 'tot_cld_amt']}\n",
    "                     )\n",
    "name_dict = fields.set_index('name_CAFE').to_dict()['name_std']\n",
    "\n",
    "fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T08:36:37.200486Z",
     "start_time": "2018-05-02T08:36:37.160969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_CAFE</th>\n",
       "      <th>name_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precip</td>\n",
       "      <td>precip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name_CAFE name_std\n",
       "0    precip   precip"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Partial lists -----\n",
    "\n",
    "fields = pd.DataFrame( \\\n",
    "        {'name_CAFE': ['hght', 'sphum', 'temp', 'ucomp', 'vcomp'],\n",
    "         'name_std' : ['gh',   'sphum', 'temp', 'u',     'v']}\n",
    "                     )\n",
    "name_dict = fields.set_index('name_CAFE').to_dict()['name_std']\n",
    "\n",
    "fields = pd.DataFrame( \\\n",
    "        {'name_CAFE': ['t_ref_min', 't_ref_max', 't_surf', 'ps',  'precip', 'lwdn_sfc', 'lwup_sfc', 'olr',  \n",
    "                       'swdn_sfc', 'swup_toa',   'high_cld_amt', 'low_cld_amt', 'mid_cld_amt', 'tot_cld_amt'],\n",
    "         'name_std' : ['t_ref_min', 't_ref_max', 't_s',    'p_s', 'precip', 'lwf_dn_s', 'lwf_up_s', 'olwr', \n",
    "                       'swf_dn_s', 'swf_up_toa', 'high_cld_amt', 'low_cld_amt', 'mid_cld_amt', 'tot_cld_amt']}\n",
    "                     )\n",
    "name_dict = fields.set_index('name_CAFE').to_dict()['name_std']\n",
    "\n",
    "fields = pd.DataFrame( \\\n",
    "        {'name_CAFE': ['precip'],\n",
    "         'name_std' : ['precip']}\n",
    "                     )\n",
    "name_dict = fields.set_index('name_CAFE').to_dict()['name_std']\n",
    "\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T08:36:40.010198Z",
     "start_time": "2018-05-02T08:36:39.987707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initial dates to include (takes approximately 1 min 30 sec per date) -----\n",
    "init_dates = pd.date_range('2002-2','2016-5' , freq='1MS')\n",
    "\n",
    "# Ensembles to include -----\n",
    "ensembles = range(1,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load one 366 day long year to provide time array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T08:36:42.367406Z",
     "start_time": "2018-05-02T08:36:41.999027Z"
    }
   },
   "outputs": [],
   "source": [
    "path = fcst_folder + '/yr2016/mn1/OUTPUT.1/' + fcst_filename + '.nc'\n",
    "dataset = xr.open_mfdataset(path, autoclose=True)\n",
    "time_use = dataset.time[:366]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save each year and variable separately due to memory considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T03:38:42.639744Z",
     "start_time": "2018-05-02T08:37:17.143358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 1521.167345046997 sec\n",
      "2003\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 4173.270169973373 sec\n",
      "2004\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 3911.1967186927795 sec\n",
      "2005\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 3932.8436381816864 sec\n",
      "2006\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 3420.890709400177 sec\n",
      "2007\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 3781.8179755210876 sec\n",
      "2008\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 3895.825021982193 sec\n",
      "2009\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 3798.0376267433167 sec\n",
      "2010\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 2554.4368908405304 sec\n",
      "2011\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 1878.5482606887817 sec\n",
      "2012\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 2082.0910065174103 sec\n",
      "2013\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 1938.466807126999 sec\n",
      "2014\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 1221.2286267280579 sec\n",
      "2015\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 1203.7032833099365 sec\n",
      "2016\n",
      "----------\n",
      "precip\n",
      "   Elapsed: 560.9949703216553 sec\n"
     ]
    }
   ],
   "source": [
    "years = range(2002,2017)\n",
    "months = range(1,13)\n",
    "ensembles = range(1,12)\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    print('----------')\n",
    "    for idx, variable in enumerate(fields['name_CAFE']):\n",
    "        print(variable)\n",
    "        \n",
    "        savename = 'cafe.fcst.v1.atmos.' + fields['name_std'][idx] + '.' + str(year) + '.clim.nc'\n",
    "        try:\n",
    "            temp = xr.open_mfdataset('/OSM/CBR/OA_DCFP/data/intermediate_products/pylatte_climatologies/' + savename, autoclose=True)\n",
    "            print('    Already exists')\n",
    "        except:\n",
    "            \n",
    "            fcst_list = []\n",
    "            for month in months:\n",
    "\n",
    "                ens_list = []\n",
    "                ens = []\n",
    "                empty = True\n",
    "                for ie, ensemble in enumerate(ensembles):\n",
    "\n",
    "                    path = fcst_folder + '/yr' + str(year) + '/mn' + str(month) + \\\n",
    "                           '/OUTPUT.' + str(ensemble) + '/' + fcst_filename + '.nc'\n",
    "\n",
    "                    # Try to stack ensembles into a list -----\n",
    "                    try:\n",
    "                        dataset = xr.open_mfdataset(path, autoclose=True)[variable]\n",
    "                        if 'latb' in dataset.dims:\n",
    "                            dataset = dataset.rename({'latb':'lat_2','lonb':'lon_2'})\n",
    "                        ens_list.append(dataset.rename(fields['name_std'][idx]))\n",
    "                        ens.append(ie+1)\n",
    "                        empty = False\n",
    "                    except OSError:\n",
    "                        # File does not exist -----\n",
    "                        pass\n",
    "\n",
    "                # Concatenate ensembles -----\n",
    "                if empty == False:\n",
    "                    ens_object = xr.concat(ens_list, dim='ensemble')\n",
    "                    ens_object['ensemble'] = ens\n",
    "\n",
    "                    # Stack concatenated ensembles into a list for each month in a year -----                       \n",
    "                    fcst_list.append(ens_object)\n",
    "\n",
    "            # Concatenate all months within year -----\n",
    "            ds = xr.concat(fcst_list, dim='time')\n",
    "\n",
    "            # Rechunk for chunksizes of at least 1,000,000 elements -----\n",
    "            ds = utils.prune(ds.chunk(chunks={'ensemble' : len(ds.ensemble), \n",
    "                                              'time' : len(ds.time)}).squeeze())\n",
    "\n",
    "            # Make month_day array of month-day -----\n",
    "            m = np.array([str(i).zfill(2) + '-' for i in ds.time.dt.month.values])\n",
    "            d = np.array([str(i).zfill(2)  for i in ds.time.dt.day.values])\n",
    "            md = np.core.defchararray.add(m, d)\n",
    "\n",
    "            # Replace time array with month_day array and groupby -----\n",
    "            ds['time'] = md\n",
    "            ds_clim = ds.groupby('time').mean(dim=['time','ensemble'],keep_attrs=True)\n",
    "\n",
    "            # Fill time with presaved time -----\n",
    "            ds_clim['time'] = time_use\n",
    "            ds_clim.time.attrs['long_name'] = 'time'\n",
    "            ds_clim.time.attrs['cartesian_axis'] = 'T'\n",
    "            ds_clim.time.attrs['calendar_type'] = 'JULIAN'\n",
    "            ds_clim.time.attrs['bounds'] = 'time_bounds'\n",
    "\n",
    "            # Save and delete -----\n",
    "            with utils.timer():\n",
    "                ds_clim.to_netcdf(path='/OSM/CBR/OA_DCFP/data/intermediate_products/pylatte_climatologies/' + savename,\n",
    "                                  mode = 'w',\n",
    "                                  encoding = {'time':{'dtype':'float','calendar':'JULIAN',\n",
    "                                                      'units':'days since 0001-01-01 00:00:00'}}) \n",
    "\n",
    "            del ds, ds_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pylatte_env]",
   "language": "python",
   "name": "conda-env-pylatte_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
